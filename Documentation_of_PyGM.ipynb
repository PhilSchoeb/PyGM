{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#FOPPL grammar rules adapted to Python\n",
        "The idea is to use normal Python syntax for control structures, function calls, and assignments that mirror FOPPL's 8 grammar constructs.\n",
        "\n",
        "1. Variables (v) and constants (c): \\\\\n",
        "In Python, variables can be assigned directly, and constants are just literal values:\n",
        "\n",
        "```python\n",
        "v = 42    # variable\n",
        "c = 3.14  # constant\n",
        "```\n",
        "2. Let-bindings (let [v e1] e2):\n",
        "\n",
        "There is no special let keyword in Python, but a simple assignment followed by further code accomplishes the same structural effect. \\\\\n",
        "```python\n",
        "v = e1\n",
        "#Now use v in e2\n",
        "result = e2\n",
        "```\n",
        "\n",
        "3. Conditionals (if e1 e2 e3):\n",
        "\n",
        "```python\n",
        "if e1:\n",
        "    result = e2\n",
        "else:\n",
        "    result = e3\n",
        "```\n",
        "\n",
        "4. Function calls (f e1 ... en) and (c e1 ... en):\n",
        "\n",
        "If f is a function and c is a primitive operation (like + or *), in Python you just call them.\n",
        "```python\n",
        "result = f(e1, e2, ..., en)\n",
        "result = e1 + e2  # if c is the '+' operation\n",
        "```\n",
        "\n",
        "5. Sampling (sample e) and Observing (observe e1 e2):\n",
        "\n",
        "Note: Sample can be an Assignment or an Expr. We can therefore call a \"sample\" as argument (e1) in an \"observe\"\n",
        "```python\n",
        "x = sample(e)\n",
        "observe(e1, e2)\n",
        "```\n",
        "\n",
        "6. Function Definitions (defn f [v1 ... vn] e) q:\n",
        "\n",
        "```python\n",
        "def f(v1, v2, ..., vn):\n",
        "    return e\n",
        "# Then q follows as normal Python statements\n",
        "q\n",
        "```\n",
        "\n",
        "7. Foreach (foreach c [v1 e1 ... vn en] e1' ... e'k):\n",
        "\n",
        "```python\n",
        "for i in range(c):\n",
        "    v1 = e1[i]\n",
        "    ...\n",
        "    vn = en[i]\n",
        "    # Then execute e1', e2', ..., e'k inside the loop\n",
        "```\n",
        "\n",
        "8. Loop (loop c e f e1 ... en):\n",
        "\n",
        "```python\n",
        "# Assume c is an integer, e is some initial value, f is a function, and\n",
        "# e1, e2, ..., en are expressions producing values.\n",
        "a1 = e1\n",
        "a2 = e2\n",
        "...\n",
        "an = en\n",
        "# Repeat the application of f, incrementing the index each time\n",
        "for i in range(c):\n",
        "    v = f(i, v, a1, a2, ..., an)\n",
        "# After c steps, v holds the final result that would appear at the end of the desugared let chain.\n",
        "```"
      ],
      "metadata": {
        "id": "7BmNL0NjuWaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Examples of models written in PyGM:\n",
        "We will use these models to help us debug as we code our translator. (TODO: Add the functionality of using an input data file)\n",
        "\n",
        "1. Example 1\n",
        "\n",
        "```python\n",
        "def sqrt(x):\n",
        "    return x ** 0.5\n",
        "\n",
        "z = sample(bernoulli(0.5))\n",
        "\n",
        "d = normal(z, 1.0)\n",
        "\n",
        "y0 = 0.25*2\n",
        "observe(d, y0)\n",
        "\n",
        "observe(z, 1)\n",
        "\n",
        "y2 = sqrt(4)\n",
        "observe(sample(normal(5, 1.0)), y2)\n",
        "\n",
        "z\n",
        "\n",
        "```\n",
        "\n",
        "2. GMM\n",
        "\n",
        "```python\n",
        "# Given data.\n",
        "data = [1.1, 2.1, 2.0, 1.9, 0.0, -0.1, -0.05]\n",
        "likes = []\n",
        "for _ in range(3):\n",
        "    mu = sample(normal(0.0, 10.0))\n",
        "    sigma = sample(gamma(1.0, 1.0))\n",
        "    likes.append(normal(mu, sigma))\n",
        "pi = sample(dirichlet([1.0, 1.0, 1.0]))\n",
        "z_prior = discrete(pi)\n",
        "for y in data:\n",
        "    z = sample(z_prior)\n",
        "    observe(likes[z], y)\n",
        "```\n",
        "3. HMM\n",
        "\n",
        "```python\n",
        "data = [0.9, 0.8, 0.7, 0.0, -0.025, -5.0, -2.0, -0.1, 0.0, 0.13, 0.45, 6, 0.2, 0.3, -1, -1]\n",
        "\n",
        "trans_dists = [\n",
        "    multinomial(1, [0.10, 0.50, 0.40]),\n",
        "    multinomial(1, [0.20, 0.20, 0.60]),\n",
        "    multinomial(1, [0.15, 0.15, 0.70])\n",
        "]\n",
        "\n",
        "likes = [\n",
        "    norm(-1.0, 1.0),\n",
        "    norm(1.0, 1.0),\n",
        "    norm(0.0, 1.0)\n",
        "]\n",
        "\n",
        "states = [sample(multinomial(1, [0.33, 0.33, 0.34]))]\n",
        "\n",
        "for i in range(16):\n",
        "    z = sample(trans_dists[states[-1]])\n",
        "    observe(likes[z], data[i])\n",
        "    append(states, z)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "1TGxyocayQ4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guide to use PyGM :\n",
        "\n",
        "Our language PyGM acts as a Bayesian approximator to the joint of latent variables conditioned on the observed variables.\n",
        "\n",
        "1. You can't name variables or functions \"zi\" or \"yi\" where i is an integer.\n",
        "2. To use the append function, instead of writing \"array.append(elem)\" ---> use \"append(array, elem)\"\n",
        "3. To use \"for loops\", there are two syntaxes to do it :    \n",
        "- \"for _ in range():\"\n",
        "\n",
        "  For this syntax, using range(), you can put 1, 2 or 3 arguments in the range function BUT they have to be constants or variable names referring to constants.\n",
        "\n",
        "- \"for _ in stored_var:\"\n",
        "\n",
        "  For this syntax, using a stored variable, stored_var has to have been declared as an array/list before the loop.\n",
        "\n",
        "In both cases, the target \"\\_\" can be named as you like. After the for loop, the variable \"\\_\" will be stored in the environment with the last value it was assigned.\n",
        "\n",
        "  4. To use distributions you must respect the following syntax for each one :    \n",
        "\n",
        "- Normal : \"norm(mu, sigma)\"\n",
        "- Gamma : \"gamma(alpha, theta)\"\n",
        "- Dirichlet : \"dirichlet([elem1, elem2, ..., elemk])\"\n",
        "- Beta : \"beta(alpha, beta_arg)\"\n",
        "- Binomial : \"binomial(n, p)\"\n",
        "- Discrete : \"multinomial(1, [prob1, prob2, ..., probk])\"\n",
        "- Multinomial : \"multinomial(n, [prob1, prob2, ..., probk])\"\n",
        "- Poisson : \"poisson(lambda)\"\n",
        "- Bernoulli : \"bernoulli(p)\"\n",
        "\n",
        "5. The follow porgramming tools have not yet been implemented :\n",
        "\n",
        "- if statement\n",
        "- function definition\n",
        "- any function that is not part of the basic operations (+, -, \\*, /, **, %)\n"
      ],
      "metadata": {
        "id": "oquUWDibjB6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import source codes from Drive"
      ],
      "metadata": {
        "id": "VjyD2wEdeGqp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBsa8b6Ce9-a"
      },
      "outputs": [],
      "source": [
        "import ast, copy\n",
        "import os\n",
        "from scipy.stats import norm, gamma, poisson, dirichlet, beta, binom, multinomial\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Set, List, Tuple, Dict, Any\n",
        "import re\n",
        "from copy import deepcopy\n",
        "import math\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#drive.mount('/content/drive')\n",
        "#shared_folder_path = '/content/drive/My Drive/Source_code_examples'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Translator"
      ],
      "metadata": {
        "id": "MjzTyOaDeNFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Graph:\n",
        "    def __init__(self, v, a, p, y):\n",
        "        \"\"\"\n",
        "        v is the set of vertices : {x, y}\n",
        "        a is the set of arcs (directed, from x to y here) : {(x, y)}\n",
        "        p is a dictionary from vertex to mass/density function : {x : distribution_1, y : distribution_2}\n",
        "        y is a dictionary from vertex to its observed value : {y : observed_value}\n",
        "        \"\"\"\n",
        "        self.v = v\n",
        "        self.a = a\n",
        "        self.p = p\n",
        "        self.y = y\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Graph(\\nv={self.v},\\na={self.a},\\np={self.p_to_string()},\\ny={self.y})\"\n",
        "\n",
        "    def p_to_string(self):\n",
        "        string = \"{\"\n",
        "        for key, value in self.p.items():\n",
        "            string += (f\"{key}: {str(value)}\\n\")\n",
        "        return string[:-1] + \"}\"\n",
        "\n",
        "    def print_p(self):\n",
        "      for key, value in self.p.items():\n",
        "        print(key)\n",
        "        print(ast.dump(value, indent=4))\n",
        "\n",
        "    def print_y(self):\n",
        "      for key, value in self.y.items():\n",
        "        print(key)\n",
        "        print(ast.dump(value, indent=4))\n",
        "\n",
        "\n",
        "def create_empty_graph():\n",
        "    graph = Graph(set(), set(), {}, {})\n",
        "    return graph\n",
        "\n",
        "def combine_disjoint_graphs(g1, g2):\n",
        "    \"\"\"\n",
        "    Combines two graphs into one, ensuring node and attribute names are unique\n",
        "    to avoid conflicts when the graphs share nodes with the same names.\n",
        "    \"\"\"\n",
        "    # If g1 or g2 is a list of graph\n",
        "    if isinstance(g1, list):\n",
        "        new_g1 = create_empty_graph()\n",
        "        for graph in g1:\n",
        "            new_g1 = combine_disjoint_graphs(new_g1, graph)\n",
        "        g1 = new_g1\n",
        "    if isinstance(g2, list):\n",
        "        new_g2 = create_empty_graph()\n",
        "        for graph in g2:\n",
        "            new_g2 = combine_disjoint_graphs(new_g2, graph)\n",
        "        g2 = new_g2\n",
        "\n",
        "    combined_graph = Graph(g1.v.union(g2.v), g1.a.union(g2.a), {**g1.p, **g2.p}, {**g1.y, **g2.y})\n",
        "    return combined_graph\n",
        "\n",
        "def visualize_graph_variables(graph):\n",
        "    print(str(graph))\n",
        "    return\n",
        "\n",
        "def copy_graph(graph):\n",
        "    # For list of graphs\n",
        "    if isinstance(graph, list):\n",
        "        new_graph_list = []\n",
        "        for g in graph:\n",
        "            new_graph_list.append(copy_graph(g))\n",
        "        return new_graph_list\n",
        "\n",
        "    new_graph = Graph(graph.v.copy(), graph.a.copy(), graph.p.copy(), graph.y.copy())\n",
        "    return new_graph\n",
        "\n",
        "# Use this function to see the vertices and the edges of a graph\n",
        "def show_graph(graph):\n",
        "    # Your vertex and edge lists\n",
        "    v=graph.v\n",
        "    a=graph.a\n",
        "\n",
        "    # Create a graph\n",
        "    G = nx.DiGraph()\n",
        "    G.add_nodes_from(v)\n",
        "    G.add_edges_from(a)\n",
        "\n",
        "    # Assign colors based on node prefix\n",
        "    color_map = []\n",
        "    for node in G.nodes:\n",
        "        if node.startswith('z'):\n",
        "            color_map.append('lightblue')  # Nodes starting with 'z' get light blue\n",
        "        elif node.startswith('y'):\n",
        "            color_map.append('lightgreen')  # Nodes starting with 'y' get light green\n",
        "\n",
        "    # Draw the graph\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    pos = nx.spring_layout(G)  # Position nodes for visualization\n",
        "    nx.draw(\n",
        "        G, pos, with_labels=True, node_size=1500, node_color=color_map,\n",
        "        font_size=25, font_weight=\"bold\", arrowsize=20\n",
        "    )\n",
        "\n",
        "    # Display the plot\n",
        "    plt.title(\"Graph Visualization of the source code\")\n",
        "    plt.show()\n",
        "\n",
        "# Function to evaluate ast.node that is deterministic :\n",
        "def partial_evaluate(node):\n",
        "    ast_to_eval = ast.Assign(targets=[ast.Name(id='result', ctx=ast.Store())], value=node)\n",
        "    ast.fix_missing_locations(ast_to_eval)\n",
        "    module = ast.Module(body=[ast_to_eval], type_ignores=[])\n",
        "    ast.fix_missing_locations(module)\n",
        "    compiled_code = compile(module, filename=\"<ast>\", mode=\"exec\")\n",
        "\n",
        "    # Prepare a namespace to store the execution result\n",
        "    namespace = {}\n",
        "    exec(compiled_code, namespace)\n",
        "\n",
        "    # Access the assigned value of \"result\"\n",
        "    result_value = namespace.get(\"result\")\n",
        "    return result_value"
      ],
      "metadata": {
        "id": "B00faeAEqt9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prototype 3 ; recursive translation\n",
        "class PPL_translator():\n",
        "    def __init__(self):\n",
        "        self.phi = True\n",
        "        self.rho = {}  # map from function names to variable values\n",
        "        self.env = {}  # map from variable names to variable values\n",
        "        self.load_rho()\n",
        "        self.lv_counter = 0  # to keep track of latent variables indexing\n",
        "        self.ov_counter = 0  # to keep track of observed variables indexing\n",
        "        self.free_vars = []\n",
        "\n",
        "    def load_rho(self):\n",
        "        #Defined functions\n",
        "        self.rho[\"norm\"] = \"logpdf\"\n",
        "        self.rho[\"gamma\"] = \"logpdf\"\n",
        "        self.rho[\"dirichlet\"] = \"logpdf\"\n",
        "        self.rho[\"beta\"] = \"logpdf\"\n",
        "        self.rho[\"binomial\"] = \"logpmf\"\n",
        "        self.rho[\"multinomial\"] = \"logpmf\"\n",
        "        self.rho[\"poisson\"] = \"logpmf\"\n",
        "        self.rho[\"bernoulli\"] = \"logpmf\"\n",
        "\n",
        "\n",
        "    def score(self, node, vertex_added):\n",
        "        if isinstance(node, ast.Call) and node.func.id in self.rho:\n",
        "            p_zi = \"p\" + vertex_added\n",
        "            dist_type = self.rho[node.func.id]\n",
        "            return ast.Assign(targets=[ast.Name(id=p_zi)], value=ast.Attribute(value=node, attr=dist_type, ctx=ast.Load()))\n",
        "        elif isinstance(node, ast.Name):\n",
        "            if bool(re.fullmatch(r'z\\d+', node.id)):  # Check if the name refers to a vertex\n",
        "                p_zi = \"p\" + vertex_added\n",
        "                return ast.Assign(targets=[ast.Name(id=p_zi)], value=node)\n",
        "\n",
        "            name_graph, name_value = self.process(node)  # After that, name_value is supposed to be an ast.Call\n",
        "            p_zi = \"p\" + vertex_added\n",
        "            dist_type = self.rho[name_value.func.id]\n",
        "            return ast.Assign(targets=[ast.Name(id=p_zi)], value=ast.Attribute(value=name_value, attr=dist_type, ctx=ast.Load()))\n",
        "\n",
        "        elif isinstance(node, ast.Subscript):\n",
        "            p_zi = \"p\" + vertex_added\n",
        "            distr_list = node.value\n",
        "            new_distr_elts = []\n",
        "            for distr in distr_list.elts:\n",
        "                assert isinstance(distr, ast.Call), \"Element in subscript is not a Call\"\n",
        "                dist_type = self.rho[distr.func.id]\n",
        "                new_distr_elts.append(ast.Attribute(value=distr, attr=dist_type, ctx=ast.Load()))\n",
        "            return ast.Assign(targets=[ast.Name(id=p_zi)], value=ast.Subscript(value=ast.List(elts=new_distr_elts), slice=node.slice, ctx=ast.Load()))\n",
        "        else:\n",
        "            raise ValueError(f\"invalid argument for sample: {type(node).__name__}\")\n",
        "\n",
        "    def search_free_vars(self, node):\n",
        "        if isinstance(node, ast.Name):\n",
        "            if bool(re.fullmatch(r'z\\d+', node.id)):\n",
        "                  self.free_vars.append(node.id)\n",
        "\n",
        "        for child in ast.iter_child_nodes(node):\n",
        "            self.search_free_vars(child)\n",
        "\n",
        "\n",
        "\n",
        "    def process(self, node):\n",
        "        \"\"\"\n",
        "        Recursively process an AST node and return the graph fragment corresponding to it.\n",
        "        \"\"\"\n",
        "        if isinstance(node, ast.Module):\n",
        "            # This is the root\n",
        "            length = len(node.body)\n",
        "            assert length > 0, \"By convention, program to translate has to have at least 1 line of code\"\n",
        "            # assert isinstance(node.body[length-1], ast.Expr), \"By convention, last line of the program has to be an ast.Expr node indicading the return value\"\n",
        "            final_graph = create_empty_graph()\n",
        "\n",
        "            for i in range(length):\n",
        "                statement = node.body[i]\n",
        "                graph, value = self.process(statement)\n",
        "                final_graph = combine_disjoint_graphs(final_graph, graph)\n",
        "            # return the graph and value of the last statement aka the ast.Expr\n",
        "            # node that indicates the return value\n",
        "            return final_graph, value\n",
        "\n",
        "        elif isinstance(node, ast.Assign):\n",
        "            # Handle assignment statements\n",
        "            target = node.targets[0].id  # Assuming single variable on the left\n",
        "            graph, expression = self.process(node.value)  # Process the right-hand side\n",
        "            self.env[target] = (graph, expression)  # Save variable for future use\n",
        "            return graph, ast.Assign(targets=[ast.Name(id=target)], value=expression)\n",
        "\n",
        "        elif isinstance(node, ast.Call):\n",
        "            # Handle function calls\n",
        "            func_name = node.func.id\n",
        "            if func_name == \"sample\":\n",
        "                # Special handling for `sample`\n",
        "                dist_graph, dist_value = self.process(node.args[0])  # Process the argument\n",
        "                num_v = self.lv_counter\n",
        "                self.lv_counter += 1\n",
        "\n",
        "                vertex_added = \"z\" + str(num_v)\n",
        "                dist_graph.v.add(vertex_added)\n",
        "\n",
        "                self.free_vars = []\n",
        "                self.search_free_vars(dist_value)\n",
        "\n",
        "                for var in self.free_vars:\n",
        "                    dist_graph.a.add(tuple([var, vertex_added]))\n",
        "\n",
        "                dist_graph.p[vertex_added] = self.score(dist_value, vertex_added)\n",
        "                return dist_graph, ast.Name(id=vertex_added)\n",
        "\n",
        "            elif func_name == \"observe\":\n",
        "                # Special handling for `observe`\n",
        "                dist_graph, dist_value = self.process(node.args[0])  # Process the distribution\n",
        "                obs_graph, obs_value = self.process(node.args[1])  # Process the observed value\n",
        "\n",
        "                if isinstance(obs_graph, list):\n",
        "                    for graph in obs_graph:\n",
        "                        if graph.v != set():\n",
        "                            raise(\"observed value is not deterministic\")\n",
        "                else:\n",
        "                    if obs_graph.v != set():\n",
        "                        raise(\"observed value is not deterministic\")\n",
        "\n",
        "                combined_graph = combine_disjoint_graphs(dist_graph, obs_graph)\n",
        "                num_v = self.ov_counter\n",
        "                self.ov_counter += 1\n",
        "                vertex_added = \"y\" + str(num_v)\n",
        "\n",
        "                score_func = self.score(dist_value, vertex_added)\n",
        "                self.free_vars = []\n",
        "                self.search_free_vars(score_func)\n",
        "\n",
        "                for var in self.free_vars:\n",
        "                    combined_graph.a.add(tuple([var, vertex_added]))\n",
        "\n",
        "                combined_graph.v.add(vertex_added)\n",
        "                combined_graph.p[vertex_added] = score_func\n",
        "                combined_graph.y[vertex_added] = obs_value\n",
        "\n",
        "                return combined_graph, obs_value\n",
        "\n",
        "            elif func_name == \"append\":\n",
        "                element = node.args[1]\n",
        "                element_graph, element_value = self.process(element)\n",
        "                array = self.env[node.args[0].id][1]\n",
        "                graph_array = self.env[node.args[0].id][0]\n",
        "                array.elts.append(element_value)\n",
        "                graph_array.append(element_graph)\n",
        "                return element_graph, None\n",
        "\n",
        "            elif func_name == \"range\":\n",
        "                # Assume deterministic range for now\n",
        "                # Also assume range args are ast.Constant nodes (can change later if needed)\n",
        "                args = []\n",
        "                for arg in node.args:\n",
        "                    arg_graph, arg_value = self.process(arg)  # arg_graph should be empty, and arg_value should be ast.Constant even if arg is ast.Name\n",
        "                    args.append(arg_value)\n",
        "                if len(node.args) == 1:\n",
        "                    range_return = list(range(args[0].value))\n",
        "                    return create_empty_graph(), ast.List(elts=[ast.Constant(value=x) for x in range_return], ctx=ast.Load())\n",
        "                elif len(node.args) == 2:\n",
        "                    range_return = list(range(args[0].value, args[1].value))\n",
        "                    return create_empty_graph(), ast.List(elts=[ast.Constant(value=x) for x in range_return], ctx=ast.Load())\n",
        "                elif len(node.args) == 3:\n",
        "                    range_return = list(range(args[0].value, args[1].value, args[2].value))\n",
        "                    return create_empty_graph(), ast.List(elts=[ast.Constant(value=x) for x in range_return], ctx=ast.Load())\n",
        "                else:\n",
        "                    raise ValueError(\"Invalid number of arguments for range\")\n",
        "\n",
        "            else:\n",
        "                # Generic function call handling\n",
        "                graph = create_empty_graph()\n",
        "                args_list = []\n",
        "                if node.func.id in self.rho:\n",
        "                    for arg in node.args:\n",
        "                        arg_graph, arg_value = self.process(arg)\n",
        "                        graph = combine_disjoint_graphs(graph, arg_graph)\n",
        "                        args_list.append(arg_value)\n",
        "                    name = node.func.id\n",
        "                    value = ast.Call(func=ast.Name(id=name, ctx=ast.Load()), args=args_list, keywords=[])\n",
        "                else:\n",
        "                    raise ValueError(f\"Unknown function: {node.func.id}\")\n",
        "\n",
        "                return graph, value\n",
        "\n",
        "        elif isinstance(node, ast.Expr):\n",
        "            expr_graph, expr_value = self.process(node.value)\n",
        "            return expr_graph, ast.Expr(value=expr_value)\n",
        "\n",
        "        elif isinstance(node, ast.Subscript):\n",
        "            index_graph, index_value = self.process(node.slice)\n",
        "            value_graph, value_value = self.process(node.value)\n",
        "            # Evaluate when index is deterministic :\n",
        "            if index_graph.v == set():\n",
        "                if isinstance(index_value, ast.Constant):\n",
        "                    index = partial_evaluate(index_value)\n",
        "                    elem_value = value_value.elts[index]  # Assuming value_value is ast.List\n",
        "                    elem_graph = value_graph[index]\n",
        "                    return elem_graph, elem_value\n",
        "\n",
        "            final_graph = combine_disjoint_graphs(value_graph, index_graph)\n",
        "            return final_graph, ast.Subscript(value=value_value, slice=index_value, ctx=ast.Load())\n",
        "\n",
        "        elif isinstance(node, ast.List):\n",
        "            l = []\n",
        "            # lgraph = create_empty_graph()\n",
        "            lgraph = []\n",
        "            for elem in node.elts:\n",
        "                elem_graph, elem_value = self.process(elem)\n",
        "                # lgraph = combine_disjoint_graphs(lgraph, elem_graph)\n",
        "                lgraph.append(elem_graph)\n",
        "                l.append(elem_value)\n",
        "            return lgraph, ast.List(elts=l, ctx=ast.Load())  # ast.List returns a list of graphs\n",
        "\n",
        "        elif isinstance(node, ast.Name):\n",
        "            # Variable reference (return a minimal graph with this variable)\n",
        "            if node.id in self.env:\n",
        "                if isinstance(self.env[node.id][1], ast.List):  # This is to make it so when we refer an array in a loop, it computes the current array and not the final array (after next append functions)\n",
        "                    graph, value = self.env[node.id]\n",
        "                    return copy_graph(graph), copy.deepcopy(value)\n",
        "                else:\n",
        "                    graph, value = self.env[node.id]\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown variable: {node.id}\")\n",
        "            return graph, value\n",
        "\n",
        "\n",
        "        elif isinstance(node, ast.For):\n",
        "            for_var = node.target.id\n",
        "            iter_graph, iter_value = self.process(node.iter)  # We will assume a deterministic iter for now\n",
        "            for_graph = create_empty_graph()\n",
        "            for elem in iter_value.elts:\n",
        "                self.env[for_var] = (iter_graph, elem)\n",
        "                for statement in node.body:\n",
        "                    statement_graph, statement_value = self.process(statement)\n",
        "                    for_graph = combine_disjoint_graphs(for_graph, statement_graph)\n",
        "            return for_graph, ast.For(target=node.target, iter=node.iter, body=node.body)  # Not sure about the expression to return here\n",
        "\n",
        "\n",
        "        elif isinstance(node, ast.Constant):\n",
        "            # Literal value (return an empty graph)\n",
        "            return create_empty_graph(), ast.Constant(value=node.value)\n",
        "\n",
        "        elif isinstance(node, ast.BinOp):\n",
        "            left_graph, left_value = self.process(node.left)\n",
        "            right_graph, right_value = self.process(node.right)\n",
        "            op_graph, op_value = self.process(node.op)\n",
        "\n",
        "            # Partial evaluation\n",
        "            if left_graph.v == set() and right_graph.v == set():\n",
        "                result = partial_evaluate(ast.BinOp(left_value, op_value, right_value))\n",
        "                return create_empty_graph(), ast.Constant(value=result)\n",
        "\n",
        "            return combine_disjoint_graphs(left_graph, right_graph), ast.BinOp(left_value, op_value, right_value)\n",
        "\n",
        "        elif isinstance(node, ast.UnaryOp):\n",
        "            operand_graph, operand_value = self.process(node.operand)\n",
        "\n",
        "            # Partial evaluation\n",
        "            if operand_graph.v == set():\n",
        "                result = partial_evaluate(ast.UnaryOp(node.op, operand_value))\n",
        "                return create_empty_graph(), ast.Constant(value=result)\n",
        "            op_graph, op_value = self.process(node.op)\n",
        "\n",
        "            return combine_disjoint_graphs(operand_graph, op_graph), ast.UnaryOp(op_value, operand_value)\n",
        "\n",
        "        elif isinstance(node, ast.Add):\n",
        "            return create_empty_graph(), ast.Add()\n",
        "\n",
        "        elif isinstance(node, ast.Sub):\n",
        "            return create_empty_graph(), ast.Sub()\n",
        "\n",
        "        elif isinstance(node, ast.Mult):\n",
        "            return create_empty_graph(), ast.Mult()\n",
        "\n",
        "        elif isinstance(node, ast.Div):\n",
        "            return create_empty_graph(), ast.Div()\n",
        "\n",
        "        elif isinstance(node, ast.Pow):\n",
        "            return create_empty_graph(), ast.Pow()\n",
        "\n",
        "        elif isinstance(node, ast.Mod):\n",
        "            return create_empty_graph(), ast.Mod()\n",
        "\n",
        "        elif isinstance(node, ast.USub):\n",
        "            return create_empty_graph(), ast.USub()\n",
        "\n",
        "        else:\n",
        "            # Unhandled nodes (for simplicity, treat them as no-op)\n",
        "            raise ValueError(f\"Unhandled node type: {type(node).__name__}\")\n",
        "            return create_empty_graph(), None"
      ],
      "metadata": {
        "id": "iw9PXj1Nc3Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example function to parse and translate Python source code\n",
        "def parse_and_translate(source_code: str) -> Tuple[Graph, Any]:\n",
        "    \"\"\"\n",
        "    Parse Python source code and translate it into a Graph and deterministic expression.\n",
        "\n",
        "    Parameters:\n",
        "        source_code (str): The Python source code to translate.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Graph, Any]: The combined graphical model and the final deterministic expression.\n",
        "    \"\"\"\n",
        "    tree = ast.parse(source_code)\n",
        "\n",
        "\n",
        "    ppl_t = PPL_translator()\n",
        "    combined_graph, expr = ppl_t.process(tree)\n",
        "    return combined_graph, expr, ppl_t.env"
      ],
      "metadata": {
        "id": "1gzMhQl0oPtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluator:"
      ],
      "metadata": {
        "id": "p0rfFiBhCpcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_one_hot_list(elts):\n",
        "    # elts are a list of ast.Constant nodes with either 0 or 1 values\n",
        "    values = [e.value for e in elts if isinstance(e, ast.Constant)]\n",
        "    return len(values) == len(elts) and sum(values) == 1 and all(v in [0,1] for v in values)\n",
        "\n",
        "def one_hot_index_list(elts):\n",
        "    values = [e.value for e in elts if isinstance(e, ast.Constant)]\n",
        "    return values.index(1)\n",
        "\n",
        "class ZYReplacer(ast.NodeTransformer):\n",
        "    def __init__(self, z, y):\n",
        "        super().__init__()\n",
        "        self.z = z\n",
        "        self.y = y\n",
        "\n",
        "    def visit_Name(self, node):\n",
        "        # For z_i\n",
        "        if node.id.startswith('z') and node.id[1:].isdigit():\n",
        "            idx = int(node.id[1:])\n",
        "            val = self.z[idx]\n",
        "            # If val is a scalar, just return a Constant\n",
        "            if isinstance(val, (int, float)):\n",
        "                return ast.Constant(value=val)\n",
        "            # If val is a list, return an ast.List of ast.Constant\n",
        "            elif isinstance(val, list):\n",
        "                return ast.List(\n",
        "                    elts=[ast.Constant(value=v) for v in val],\n",
        "                    ctx=ast.Load()\n",
        "                )\n",
        "            else:\n",
        "                # Handle other types as needed\n",
        "                return ast.Constant(value=val)\n",
        "\n",
        "        # For y_i\n",
        "        elif node.id.startswith('y') and node.id[1:].isdigit():\n",
        "            return self.y[node.id]  # already an ast.Constant\n",
        "\n",
        "        return node\n",
        "\n",
        "class OneHotIndexTransformer(ast.NodeTransformer):\n",
        "    def visit_Subscript(self, node):\n",
        "        self.generic_visit(node)\n",
        "        # Now check if the slice is a List node\n",
        "        if isinstance(node.slice, ast.List):\n",
        "            # Check if it's a one-hot list\n",
        "            if is_one_hot_list(node.slice.elts):\n",
        "                idx = one_hot_index_list(node.slice.elts)\n",
        "                node.slice = ast.Constant(value=idx)\n",
        "            else:\n",
        "                raise ValueError(\"Non one-hot vector used as index.\")\n",
        "            if isinstance(node.value, ast.List) and not hasattr(node.value, 'ctx'):\n",
        "                node.value.ctx = ast.Load()\n",
        "        return node\n",
        "\n",
        "\n",
        "def evaluate_distribution(expr, val):\n",
        "    code_ast = ast.fix_missing_locations(ast.Expression(expr))\n",
        "    code = compile(code_ast, \"<ast>\", \"eval\")\n",
        "    dist_func = eval(code)\n",
        "    return dist_func(val)\n",
        "\n",
        "def process_and_evaluate(p, y, z):\n",
        "    p_copy = deepcopy(p)\n",
        "    replacer = ZYReplacer(z, y)\n",
        "    for k in p_copy:\n",
        "        p_copy[k] = replacer.visit(p_copy[k])\n",
        "    indexer = OneHotIndexTransformer()\n",
        "    for k in p_copy:\n",
        "        p_copy[k] = indexer.visit(p_copy[k])\n",
        "\n",
        "    results = []\n",
        "    for k, assign_node in p_copy.items():\n",
        "        var_name = assign_node.targets[0].id\n",
        "        dist_expr = assign_node.value\n",
        "        def func(val):\n",
        "            return evaluate_distribution(dist_expr, val)\n",
        "\n",
        "        if var_name.startswith('pz'):\n",
        "            i = int(var_name[2:])\n",
        "            results.append(func(z[i]))\n",
        "        elif var_name.startswith('py'):\n",
        "            i = int(var_name[2:])\n",
        "            results.append(func(y[f\"y{i}\"].value))\n",
        "\n",
        "    logprob = sum(results)\n",
        "    return logprob, p_copy"
      ],
      "metadata": {
        "id": "qROzMotL_UK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Examples"
      ],
      "metadata": {
        "id": "TTpRMjMyeZ-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gmm_source_code = \"\"\"\n",
        "data = [1.1, 2.1, 2.0, 1.9, 0.0, -0.1, -0.05]\n",
        "likes = []\n",
        "for _ in range(3):\n",
        "    mu = sample(norm(0.0, 10.0))\n",
        "    sigma = sample(gamma(1.0, 1.0))\n",
        "    append(likes, norm(mu, sigma))\n",
        "pi = sample(dirichlet([1.0, 1.0, 1.0]))\n",
        "z_prior = multinomial(1, pi)\n",
        "for y in data:\n",
        "    z = sample(z_prior)\n",
        "    observe(likes[z], y)\n",
        "\"\"\"\n",
        "\n",
        "gmm_source_code_2 = \"\"\"\n",
        "data = [1.1, 2.1]\n",
        "likes = []\n",
        "for _ in range(2):\n",
        "    mu = sample(norm(0.0, 10.0))\n",
        "    sigma = sample(gamma(1.0, 1.0))\n",
        "    append(likes, norm(mu, sigma))\n",
        "pi = sample(dirichlet([1.0, 1.0]))\n",
        "z_prior = multinomial(1, pi)\n",
        "for y in data:\n",
        "    z = sample(z_prior)\n",
        "    observe(likes[z], y)\n",
        "\"\"\"\n",
        "\n",
        "hmm_source_code = \"\"\"\n",
        "data = [0.9, 0.8, 0.7, 0.0, -0.025, -5.0, -2.0, -0.1, 0.0, 0.13, 0.45, 6, 0.2, 0.3, -1, -1]\n",
        "\n",
        "trans_dists = [\n",
        "    multinomial(1, [0.10, 0.50, 0.40]),\n",
        "    multinomial(1, [0.20, 0.20, 0.60]),\n",
        "    multinomial(1, [0.15, 0.15, 0.70])\n",
        "]\n",
        "\n",
        "likes = [\n",
        "    norm(-1.0, 1.0),\n",
        "    norm(1.0, 1.0),\n",
        "    norm(0.0, 1.0)\n",
        "]\n",
        "\n",
        "states = [sample(multinomial(1, [0.33, 0.33, 0.34]))]\n",
        "\n",
        "for i in range(16):\n",
        "    z = sample(trans_dists[states[-1]])\n",
        "    observe(likes[z], data[i])\n",
        "    append(states, z)\n",
        "\"\"\"\n",
        "\n",
        "hmm_source_code_2 = \"\"\"\n",
        "data = [0.9, 0.8, 0.7, 0.0]\n",
        "\n",
        "trans_dists = [\n",
        "    multinomial(1, [0.10, 0.50, 0.40]),\n",
        "    multinomial(1, [0.20, 0.20, 0.60]),\n",
        "    multinomial(1, [0.15, 0.15, 0.70])\n",
        "]\n",
        "\n",
        "likes = [\n",
        "    norm(-1.0, 1.0),\n",
        "    norm(1.0, 1.0),\n",
        "    norm(0.0, 1.0)\n",
        "]\n",
        "\n",
        "states = [sample(multinomial(1, [0.33, 0.33, 0.34]))]\n",
        "\n",
        "for y in data:\n",
        "    z = sample(trans_dists[states[-1]])\n",
        "    observe(likes[z], y)\n",
        "    append(states, z)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "freBQrDJB46X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GMM1"
      ],
      "metadata": {
        "id": "RGcwbYlGC-_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_variables = [\n",
        "    1,  # mu_1\n",
        "    2,  # mu_2\n",
        "    3,  # mu_3\n",
        "    4,  # sigma_1\n",
        "    5,  # sigma_2\n",
        "    6,  # sigma_3\n",
        "    [0.2, 0.3, 0.5],  # pi (mixing weights as a single vector)\n",
        "    [1, 0, 0],  # z_1 (one-hot encoding for cluster assignment)\n",
        "    [0, 1, 0],  # z_2\n",
        "    [0, 0, 1],  # z_3\n",
        "    [1, 0, 0],  # z_4\n",
        "    [0, 1, 0],  # z_5\n",
        "    [0, 0, 1],  # z_6\n",
        "    [1, 0, 0]   # z_7\n",
        "]\n",
        "source_code = gmm_source_code\n",
        "\n",
        "graph, expr, vars = parse_and_translate(source_code)\n",
        "# print(graph)\n",
        "# print(\"\\n\")\n",
        "# graph.print_p()\n",
        "# print(\"\\n\")\n",
        "# graph.print_y()\n",
        "# print(\"\\n\")\n",
        "# print(\"Variables:\\n\", vars)\n",
        "\n",
        "logprob, _ = process_and_evaluate(graph.p, graph.y, latent_variables)\n",
        "print(\"Sum of all logprob:\", logprob)\n",
        "print(\"Product of all prob\", math.exp(logprob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYL7AwmL7SLj",
        "outputId": "e22c2859-cc9f-4bd9-d5e9-ccd8d13c99d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of all logprob: -42.67022133991871\n",
            "Product of all prob 2.941428733159413e-19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product of all evaluations: 2.9414287331594206e-19"
      ],
      "metadata": {
        "id": "UfOXayJo7P0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GMM2"
      ],
      "metadata": {
        "id": "3uhR8nMrDBbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_variables = [\n",
        "    1,  # mu_1\n",
        "    2,  # mu_2\n",
        "    3,  # sigma_1\n",
        "    4,  # sigma_2\n",
        "    [0.2, 0.8],  # pi (mixing weights as a single vector)\n",
        "    [1, 0],  # z_1 (one-hot encoding for cluster assignment)\n",
        "    [0, 1],  # z_2\n",
        "]\n",
        "source_code = gmm_source_code_2\n",
        "\n",
        "graph, expr, vars = parse_and_translate(source_code)\n",
        "\n",
        "# print(graph)\n",
        "# print(\"\\n\")\n",
        "# graph.print_p()\n",
        "# print(\"\\n\")\n",
        "# graph.print_y()\n",
        "# print(\"\\n\")\n",
        "# print(\"Variables:\\n\", vars)\n",
        "logprob, _ = process_and_evaluate(graph.p, graph.y, latent_variables)\n",
        "print(\"Sum of all logprob:\", logprob)\n",
        "print(\"Product of all prob\", math.exp(logprob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQYBF7xxASw7",
        "outputId": "dba33e92-497b-4201-fb0c-fb118243fb42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of all logprob: -16.269509824234927\n",
            "Product of all prob 8.594916464592117e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product of all evaluations: 8.594916464592108e-08"
      ],
      "metadata": {
        "id": "BrVEB8Uu7SJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HMM1"
      ],
      "metadata": {
        "id": "hqaG9aXbDHB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_variables = [\n",
        "    [1, 0, 0],  # states[0] (initial state, one-hot encoded)\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 1],\n",
        "    [1, 0, 0],\n",
        "    [0, 1, 0],\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 1],\n",
        "    [1, 0, 0],\n",
        "    [0, 1, 0],\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 1],\n",
        "    [1, 0, 0],\n",
        "    [0, 1, 0],\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 1],\n",
        "    [1, 0, 0],\n",
        "    [0, 1, 0]\n",
        "]\n",
        "source_code = hmm_source_code\n",
        "graph, expr, vars = parse_and_translate(source_code)\n",
        "[0.0, 1.0, 0.0, 1.0, [0.5, 0.5], [0,1], [1,0]]\n",
        "logprob, _ = process_and_evaluate(graph.p, graph.y, latent_variables)\n",
        "print(\"Sum of all logprob:\", logprob)\n",
        "print(\"Product of all prob\", math.exp(logprob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR_jJXg4Bd6j",
        "outputId": "79004611-b784-42ab-d3df-cf75a6c3d31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of all logprob: -66.5625237305059\n",
            "Product of all prob 1.2366968149519487e-29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product of all evaluations: 1.2366968149519645e-29"
      ],
      "metadata": {
        "id": "cCW-waT37Tuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HMM2"
      ],
      "metadata": {
        "id": "RvsGgwhgDJl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_variables = [\n",
        "    [1, 0, 0],  # states[0] (initial state, one-hot encoded)\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 1],\n",
        "    [1, 0, 0],\n",
        "    [0, 1, 0]\n",
        "]\n",
        "\n",
        "source_code = hmm_source_code_2\n",
        "\n",
        "graph, expr, vars = parse_and_translate(source_code)\n",
        "[0.0, 1.0, 0.0, 1.0, [0.5, 0.5], [0,1], [1,0]]\n",
        "\n",
        "logprob, _ = process_and_evaluate(graph.p, graph.y, latent_variables)\n",
        "print(\"Sum of all logprob:\", logprob)\n",
        "print(\"Product of all prob\", math.exp(logprob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-GjcYeeCKiC",
        "outputId": "ea65399f-49b4-45b6-c73d-04de57604942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of all logprob: -10.848656727112065\n",
            "Product of all prob 1.943069108809343e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product of all evaluations: 1.9430691088093445e-05"
      ],
      "metadata": {
        "id": "On35qK-47W1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference Engine:\n"
      ],
      "metadata": {
        "id": "8K02ktC54Hcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DualTreeTransformer:\n",
        "    def __init__(self, tree1, tree2):\n",
        "        self.tree1 = tree1  # Fully evaluated\n",
        "        self.tree2 = tree2  # Partially evaluated\n",
        "\n",
        "    def transform(self):\n",
        "        # Start transforming tree2 using tree1 as a reference\n",
        "        return self._traverse_and_transform(self.tree1, self.tree2)\n",
        "\n",
        "    def _traverse_and_transform(self, node1, node2):\n",
        "        if isinstance(node2, ast.Name):\n",
        "            # Check if the criteria for modification are met\n",
        "            if bool(re.fullmatch(r'z\\d+', node2.id)) and isinstance(node1, ast.Constant):\n",
        "                # Replace node2 with the value from node1\n",
        "                return ast.Constant(value=node1.value, kind=None)\n",
        "\n",
        "        # Ensure both nodes have children and traverse them\n",
        "        for field, value in ast.iter_fields(node2):\n",
        "            if isinstance(value, list):\n",
        "                new_values = []\n",
        "                for i, item in enumerate(value):\n",
        "                    if isinstance(item, ast.AST):\n",
        "                        # Recursively transform child nodes in both trees\n",
        "                        new_item = self._traverse_and_transform(\n",
        "                            getattr(node1, field)[i] if hasattr(node1, field) else None,\n",
        "                            item\n",
        "                        )\n",
        "                        new_values.append(new_item)\n",
        "                    else:\n",
        "                        new_values.append(item)\n",
        "                setattr(node2, field, new_values)\n",
        "            elif isinstance(value, ast.AST):\n",
        "                # Recursively transform single child nodes\n",
        "                new_node = self._traverse_and_transform(\n",
        "                    getattr(node1, field, None),\n",
        "                    value\n",
        "                )\n",
        "                setattr(node2, field, new_node)\n",
        "        return node2\n",
        "\n",
        "\n",
        "def combine_ps(p_all_eval, p_partially_eval):\n",
        "    # Assume same p structure for both\n",
        "    for key_eval, value_eval in p_all_eval.items():\n",
        "        key_p_eval = key_eval\n",
        "        value_p_eval = p_partially_eval[key_p_eval]\n",
        "        start_node_eval = value_eval.value\n",
        "        start_node_p_eval = value_p_eval.value\n",
        "\n",
        "        transformer = DualTreeTransformer(start_node_eval, start_node_p_eval)\n",
        "        node_now_eval = transformer.transform()\n",
        "\n",
        "        p_partially_eval[key_p_eval] = node_now_eval\n",
        "    return p_partially_eval"
      ],
      "metadata": {
        "id": "_6XXW600drjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ast_to_python_value(node):\n",
        "    \"\"\"\n",
        "    Convert an AST node (like Constant or List of Constants) to a Python value.\n",
        "    Adjust this function depending on the node types you expect.\n",
        "    \"\"\"\n",
        "    if isinstance(node, ast.Constant):\n",
        "        return node.value\n",
        "    elif isinstance(node, ast.List):\n",
        "        return [ast_to_python_value(e) for e in node.elts]\n",
        "    # If you have other node types to handle, add them here\n",
        "    # For now, assume we only deal with Constants or Lists of Constants.\n",
        "    raise ValueError(\"Unsupported node type for conversion: {}\".format(type(node)))\n",
        "\n",
        "def find_z_values_in_ast(unfilled_node, filled_node, z_values):\n",
        "    \"\"\"\n",
        "    Recursively compare unfilled_node and filled_node.\n",
        "    Whenever we encounter a Name node referencing 'zX' in unfilled_node\n",
        "    and a non-Name node in filled_node, record that mapping in z_values.\n",
        "    \"\"\"\n",
        "    # If unfilled_node is a Name referencing zX and filled_node is not a Name,\n",
        "    # we have found the value of zX.\n",
        "    if isinstance(unfilled_node, ast.Name) and unfilled_node.id.startswith('z'):\n",
        "        if not isinstance(filled_node, ast.Name):\n",
        "            # Extract the integer index from 'zX'\n",
        "            index = int(unfilled_node.id[1:])\n",
        "            z_values[index] = filled_node\n",
        "        return\n",
        "\n",
        "    # If both are lists, compare element by element\n",
        "    if isinstance(unfilled_node, list) and isinstance(filled_node, list):\n",
        "        for u_node, f_node in zip(unfilled_node, filled_node):\n",
        "            find_z_values_in_ast(u_node, f_node, z_values)\n",
        "        return\n",
        "\n",
        "    # If both are AST nodes, recurse into fields\n",
        "    if isinstance(unfilled_node, ast.AST) and isinstance(filled_node, ast.AST):\n",
        "        # Recurse into matching fields\n",
        "        for field in unfilled_node._fields:\n",
        "            val_unfilled = getattr(unfilled_node, field, None)\n",
        "            val_filled = getattr(filled_node, field, None)\n",
        "            if isinstance(val_unfilled, (ast.AST, list)) and isinstance(val_filled, (ast.AST, list)):\n",
        "                find_z_values_in_ast(val_unfilled, val_filled, z_values)\n",
        "\n",
        "def extract_z_values(p_filled, p_unfilled):\n",
        "    \"\"\"\n",
        "    Given p_filled and p_unfilled dictionaries:\n",
        "    - p_unfilled and p_filled have keys like 'z5', 'y0', etc.\n",
        "    - Each value is an ast.Assign node.\n",
        "    We want to find all occurrences where p_unfilled references a z_i as a Name,\n",
        "    and p_filled has the actual value. Then return a list z where z[i] is the value of z_i.\n",
        "    \"\"\"\n",
        "    z_values = {}\n",
        "\n",
        "    # Compare each key's nodes to find where z_i appear as placeholders in unfilled\n",
        "    # and actual values in filled.\n",
        "    for key in p_unfilled.keys():\n",
        "        unfilled_node = p_unfilled[key]\n",
        "        filled_node = p_filled[key]\n",
        "        # unfilled_node and filled_node should be Assign nodes\n",
        "        # Compare their value fields\n",
        "        find_z_values_in_ast(unfilled_node.value, filled_node.value, z_values)\n",
        "\n",
        "    # Now we have a dict {index: ast_node_value} for z_i\n",
        "    # Convert them to Python objects\n",
        "    max_index = max(z_values.keys()) if z_values else -1\n",
        "    z_list = [None]*(max_index+1)\n",
        "    for i, node in z_values.items():\n",
        "        z_list[i] = ast_to_python_value(node)\n",
        "\n",
        "    return z_list\n",
        "\n",
        "def is_one_hot_list(elts):\n",
        "    # elts are a list of ast.Constant nodes with either 0 or 1 values\n",
        "    values = [e.value for e in elts if isinstance(e, ast.Constant)]\n",
        "    return len(values) == len(elts) and sum(values) == 1 and all(v in [0,1] for v in values)\n",
        "\n",
        "def one_hot_index_list(elts):\n",
        "    values = [e.value for e in elts if isinstance(e, ast.Constant)]\n",
        "    return values.index(1)\n",
        "\n",
        "class OneHotIndexTransformer(ast.NodeTransformer):\n",
        "    def visit_Subscript(self, node):\n",
        "        self.generic_visit(node)\n",
        "        # Now check if the slice is a List node\n",
        "        if isinstance(node.slice, ast.List):\n",
        "            # Check if it's a one-hot list\n",
        "            if is_one_hot_list(node.slice.elts):\n",
        "                idx = one_hot_index_list(node.slice.elts)\n",
        "                node.slice = ast.Constant(value=idx)\n",
        "            else:\n",
        "                raise ValueError(\"Non one-hot vector used as index.\")\n",
        "            if isinstance(node.value, ast.List) and not hasattr(node.value, 'ctx'):\n",
        "                node.value.ctx = ast.Load()\n",
        "        return node\n",
        "\n",
        "def evaluate_distribution(expr, val):\n",
        "    code_ast = ast.fix_missing_locations(ast.Expression(expr))\n",
        "    code = compile(code_ast, \"<ast>\", \"eval\")\n",
        "    dist_func = eval(code)\n",
        "    return dist_func(val)\n",
        "\n",
        "def eval_joint(p, y, z):\n",
        "\n",
        "    # print(\"After Initialization Values:\")\n",
        "    # for k, v in p.items():\n",
        "    #     print(k, ast.dump(v, indent=4))\n",
        "    # print(\"__________________________________________\\n\")\n",
        "\n",
        "    results = []\n",
        "    for k, assign_node in p.items():\n",
        "        var_name = assign_node.targets[0].id\n",
        "        dist_expr = assign_node.value\n",
        "        def func(val):\n",
        "            return evaluate_distribution(dist_expr, val)\n",
        "\n",
        "        if var_name.startswith('pz'):\n",
        "            i = int(var_name[2:])\n",
        "            results.append(func(z[i]))\n",
        "        elif var_name.startswith('py'):\n",
        "            i = int(var_name[2:])\n",
        "            results.append(func(y[f\"y{i}\"].value))\n",
        "\n",
        "    logprob = sum(results)\n",
        "    return logprob\n",
        "\n",
        "class YReplacer(ast.NodeTransformer):\n",
        "  #Returns a copy of the replaced node\n",
        "    def __init__(self, y):\n",
        "        self.y = y\n",
        "\n",
        "    def visit_Name(self, node):\n",
        "        # For y_i\n",
        "        if node.id.startswith('y') and node.id[1:].isdigit():\n",
        "            idx = int(node.id[1:])\n",
        "            val = self.y[idx]\n",
        "            # If val is a scalar, just return a Constant\n",
        "            if isinstance(val, (int, float)):\n",
        "                return ast.Constant(value=val)\n",
        "            # If val is a list, return an ast.List of ast.Constant\n",
        "            elif isinstance(val, list):\n",
        "                return ast.List(\n",
        "                    elts=[ast.Constant(value=v) for v in val],\n",
        "                    ctx=ast.Load()\n",
        "                )\n",
        "            else:\n",
        "                print(\"Suspicious type in Y map\")\n",
        "                return ast.Constant(value=val)\n",
        "\n",
        "        return node\n",
        "\n",
        "class ZReplacer(ast.NodeTransformer):\n",
        "  #Returns a copy of the replaced node\n",
        "      def __init__(self, zi_sample):\n",
        "          self.id = zi_sample[0]\n",
        "          self.val = zi_sample[1]\n",
        "\n",
        "      def visit_Name(self, node):\n",
        "          # For z_i\n",
        "          if node.id == self.id:\n",
        "              # If val is a scalar, just return a Constant\n",
        "              if isinstance(self.val, (int, float)):\n",
        "                  return ast.Constant(value=self.val)\n",
        "              # If val is a list, return an ast.List of ast.Constant\n",
        "              elif isinstance(self.val, list):\n",
        "                  return ast.List(\n",
        "                      elts=[ast.Constant(value=v) for v in self.val],\n",
        "                      ctx=ast.Load()\n",
        "                  )\n",
        "              else:\n",
        "                  print(\"Suspicious type for a z_i sample\")\n",
        "                  return ast.Constant(value=self.val)\n",
        "\n",
        "          return node\n",
        "\n",
        "class ZSampler(ast.NodeTransformer):\n",
        "    def get_distribution_object(self, expr):\n",
        "      \"\"\"\n",
        "      Given an AST expression (like Attribute(Call(norm(...)), 'logpdf')),\n",
        "      extract the base distribution Call node and evaluate it to get the distribution object.\n",
        "      \"\"\"\n",
        "      base_expr = expr\n",
        "      if isinstance(expr, ast.Attribute):\n",
        "          # If attr is 'logpdf', 'logpmf', etc., take expr.value which is the Call node.\n",
        "          if expr.attr in ('logpdf', 'logpmf', 'pdf', 'pmf'):\n",
        "              base_expr = expr.value\n",
        "\n",
        "      for node in ast.walk(base_expr):\n",
        "          if isinstance(node, ast.Name) and not hasattr(node, 'ctx'):\n",
        "              node.ctx = ast.Load()\n",
        "\n",
        "\n",
        "      code_ast = ast.fix_missing_locations(ast.Expression(base_expr))\n",
        "      code = compile(code_ast, \"<ast>\", \"eval\")\n",
        "      dist_obj = eval(code)\n",
        "      return dist_obj\n",
        "\n",
        "    def visit_Assign(self, assign_node):\n",
        "        var_name = assign_node.targets[0].id\n",
        "\n",
        "        # print(var_name[1:], \"being sampled\")\n",
        "\n",
        "        dist_expr = assign_node.value\n",
        "        dist_obj = self.get_distribution_object(dist_expr)\n",
        "        sampled_val = dist_obj.rvs()\n",
        "\n",
        "        if isinstance(sampled_val, np.ndarray):\n",
        "            if sampled_val.ndim == 2:\n",
        "                sampled_val = [float(x) for x in sampled_val.flatten().tolist()]\n",
        "            elif sampled_val.ndim == 1:\n",
        "                sampled_val = [float(x) for x in sampled_val.tolist()]\n",
        "            else:\n",
        "                raise NotImplementedError(\"Need to implement logic for general tensors as variables\")\n",
        "        else:\n",
        "            # Convert scalar numpy types to Python float\n",
        "            sampled_val = float(sampled_val)\n",
        "\n",
        "        return (var_name[1:], sampled_val)\n",
        "\n",
        "class BlockMetropolisWithinGibbsSampler:\n",
        "    def __init__(self, v, p, y, edges):\n",
        "        \"\"\"\n",
        "        p: dictionary of AST nodes defining pz_i and py_i\n",
        "        y: dictionary of constants for y_i\n",
        "        edges: list of (a,b) tuples indicating a->b in the graph (a is parent of b)\n",
        "        distributions_map: dict of name->distribution classes (e.g. {\"norm\": norm, ...})\n",
        "        \"\"\"\n",
        "        self.p = p\n",
        "        self.y = y\n",
        "        self.edges = edges\n",
        "        self.v = v\n",
        "        self.blocks = []\n",
        "        self.p_current = {}\n",
        "        self.initialize() # Ancestral sampling\n",
        "        self.build_blocks() # Build blocks according to the rule: {z_i} U children(z_i) U parents(children(z_i))\n",
        "\n",
        "    def initialize(self):\n",
        "        # print(\"Before Initialization Values:\")\n",
        "        # for k, v in self.p.items():\n",
        "        #     print(k, ast.dump(v, indent=4))\n",
        "        # print(\"__________________________________________\\n\")\n",
        "\n",
        "      #Replace y_i's\n",
        "        replacer = YReplacer(self.y)\n",
        "        for k in self.p:\n",
        "            self.p[k] = replacer.visit(self.p[k])\n",
        "        indexer = OneHotIndexTransformer()\n",
        "        for k in self.p:\n",
        "            self.p[k] = indexer.visit(self.p[k])\n",
        "      #Sample z_i's\n",
        "\n",
        "        self.p_current = deepcopy(self.p)\n",
        "        z = []\n",
        "        Zsampler = ZSampler()\n",
        "        indexer = OneHotIndexTransformer()\n",
        "        for k1,v1 in self.p_current.items():\n",
        "            if k1.startswith('z'):\n",
        "                sample = Zsampler.visit(self.p_current[k1])\n",
        "                z.append(sample[1])\n",
        "                # print(sample)\n",
        "                Zreplacer = ZReplacer(sample)\n",
        "                for k2,v2 in self.p_current.items():\n",
        "                    self.p_current[k2] = Zreplacer.visit(self.p_current[k2])\n",
        "                for k2,v2 in self.p_current.items():\n",
        "                    self.p_current[k2] = indexer.visit(self.p_current[k2])\n",
        "\n",
        "        # logprob = eval_joint(self.p_current, self.y, z)\n",
        "        # print(\"Sum of all logprob:\", logprob)\n",
        "        # print(\"Product of all prob\", math.exp(logprob))\n",
        "\n",
        "\n",
        "    def build_blocks(self):\n",
        "        \"\"\"\n",
        "        Partition v into blocks according to the rule: {z_i} U children(z_i) U parents(children(z_i))\n",
        "        \"\"\"\n",
        "\n",
        "        remaining_v = deepcopy(self.v)\n",
        "        remaining_edges = deepcopy(self.edges)\n",
        "        remaining_z = [node for node in remaining_v if node.startswith(\"z\")]\n",
        "        remaining_z.sort(key=lambda x: int(x[1:]))\n",
        "\n",
        "        count = 1\n",
        "        while remaining_z != []:\n",
        "            # print(\"bloc\", count )\n",
        "            count += 1\n",
        "            # Build adjacency structures for convenience\n",
        "            children_map = {}\n",
        "            parents_map = {}\n",
        "            all_nodes = set()\n",
        "            for (a,b) in remaining_edges:\n",
        "                if a not in children_map:\n",
        "                    children_map[a] = []\n",
        "                children_map[a].append(b)\n",
        "                if b not in parents_map:\n",
        "                    parents_map[b] = []\n",
        "                parents_map[b].append(a)\n",
        "            # Ensure all nodes appear even if no edges\n",
        "            for z in remaining_z:\n",
        "                if z not in children_map:\n",
        "                    children_map[z] = []\n",
        "                if z not in parents_map:\n",
        "                    parents_map[z] = []\n",
        "\n",
        "            block = set()\n",
        "            z = remaining_z.pop(0)\n",
        "            # print(z)\n",
        "            block.add(z)\n",
        "\n",
        "            # print(\"children of \", z, \" \", children_map[z])\n",
        "            for c in children_map[z]:\n",
        "                if c in remaining_v:\n",
        "                    remaining_v.remove(c)\n",
        "                # print(c, \" removed from v\")\n",
        "                if c.startswith(\"z\"):\n",
        "                    block.add(c)\n",
        "                    print(c, \" removed from z\")\n",
        "                    if c in remaining_z:\n",
        "                        remaining_z.remove(c)\n",
        "                # print(\"parents of \", c, \" \", parents_map[c])\n",
        "                for p in parents_map[c]:\n",
        "                    if p in remaining_v:\n",
        "                        remaining_v.remove(p)\n",
        "                    # print(p, \" removed from v\")\n",
        "                    if p.startswith(\"z\"):\n",
        "                        block.add(p)\n",
        "                        # print(p, \" removed from z\")\n",
        "                        if p in remaining_z:\n",
        "                            remaining_z.remove(p)\n",
        "            remaining_edges = [\n",
        "                edge\n",
        "                for edge in remaining_edges\n",
        "                if edge[0] in remaining_v and edge[1] in remaining_v\n",
        "            ]\n",
        "\n",
        "            self.blocks.append(list(block))  # store as a list\n",
        "\n",
        "            print(self.blocks)\n",
        "\n",
        "    def propose_bloc(self, block):\n",
        "        z_new = {}\n",
        "        p_prop = deepcopy(self.p)\n",
        "\n",
        "        # Replace y_i's in p_prop\n",
        "        replacer = YReplacer(self.y)\n",
        "        for k in p_prop:\n",
        "            p_prop[k] = replacer.visit(p_prop[k])\n",
        "        indexer = OneHotIndexTransformer()\n",
        "        for k in p_prop:\n",
        "            p_prop[k] = indexer.visit(p_prop[k])\n",
        "\n",
        "        #Sample z_i's in block\n",
        "        Zsampler = ZSampler()\n",
        "        indexer = OneHotIndexTransformer()\n",
        "        for k1,v1 in p_prop.items():\n",
        "            if k1 in block:\n",
        "                sample = Zsampler.visit(p_prop[k1])\n",
        "                z_new[sample[0]] = sample[1]\n",
        "                Zreplacer = ZReplacer(sample)\n",
        "                for k2,v2 in p_prop.items():\n",
        "                    p_prop[k2] = Zreplacer.visit(p_prop[k2])\n",
        "                for k2,v2 in self.p.items():\n",
        "                    p_prop[k2] = indexer.visit(p_prop[k2])\n",
        "\n",
        "        p_prop = combine_ps(p_prop, self.p_current)\n",
        "        z_prop = extract_z_values(p_prop, self.p)\n",
        "        z_current = extract_z_values(self.p_current, self.p)\n",
        "        return p_prop, z_new, z_current\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        for block in self.blocks:\n",
        "            p_proposal, z_prop, z_current = self.propose_bloc(block)\n",
        "\n",
        "            logjoint_prop = eval_joint(p_proposal, self.y, z_prop)\n",
        "            log_reverse_q = eval_joint(p_proposal, z_current)\n",
        "\n",
        "            logjoint_curr = eval_joint(self.p.current, self.y, z_current)\n",
        "            log_forward_q = eval_joint(self.p.current, z_prop)\n",
        "\n",
        "            print(logjoint_prop)\n"
      ],
      "metadata": {
        "id": "u6V4GqmD4G4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_code = gmm_source_code_2\n",
        "\n",
        "graph, expr, vars = parse_and_translate(source_code)\n",
        "\n",
        "# print(graph)\n",
        "# print(\"\\n\")\n",
        "# graph.print_p()\n",
        "# print(\"\\n\")\n",
        "# graph.print_y()\n",
        "# print(\"\\n\")\n",
        "# print(\"Variables:\\n\", vars)\n",
        "BlockMetropolisWithinGibbsSampler(graph.v, graph.p, graph.y, graph.a)\n",
        "sampler = BlockMetropolisWithinGibbsSampler(graph.v, graph.p, graph.y, graph.a)\n",
        "sampler.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "GeBg-FsrSyM3",
        "outputId": "fe6a91c5-ccf8-47f4-b4a1-bbf2e313b72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['z1', 'z5', 'z0', 'z2', 'z3', 'z6']]\n",
            "[['z1', 'z5', 'z0', 'z2', 'z3', 'z6'], ['z4']]\n",
            "[['z1', 'z5', 'z0', 'z2', 'z3', 'z6']]\n",
            "[['z1', 'z5', 'z0', 'z2', 'z3', 'z6'], ['z4']]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'z4' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f341a55e7925>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mBlockMetropolisWithinGibbsSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockMetropolisWithinGibbsSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-8a2b86164f12>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mp_proposal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropose_bloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mlogjoint_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_joint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_proposal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_prop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-8a2b86164f12>\u001b[0m in \u001b[0;36mpropose_bloc\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp_prop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZsampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_prop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mz_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mZreplacer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZReplacer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ast.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'visit_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_visit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgeneric_visit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-8a2b86164f12>\u001b[0m in \u001b[0;36mvisit_Assign\u001b[0;34m(self, assign_node)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mdist_expr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mdist_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_distribution_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_expr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0msampled_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-8a2b86164f12>\u001b[0m in \u001b[0;36mget_distribution_object\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m    192\u001b[0m       \u001b[0mcode_ast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_missing_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExpression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_expr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_ast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<ast>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m       \u001b[0mdist_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mdist_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ast>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'z4' is not defined"
          ]
        }
      ]
    }
  ]
}